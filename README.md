Structure Tree

``` text
REBench
â”œâ”€â”€ assembling.py
â”œâ”€â”€ CITATION.cff
â”œâ”€â”€ docs
â”‚Â Â  â””â”€â”€ source
â”‚Â Â      â”œâ”€â”€ cli.rst
â”‚Â Â      â”œâ”€â”€ conf.py
â”‚Â Â      â”œâ”€â”€ index.rst
â”‚Â Â      â”œâ”€â”€ installation.rst
â”‚Â Â      â”œâ”€â”€ model.rst
â”‚Â Â      â””â”€â”€ usage.rst
â”œâ”€â”€ LICENSE
â”œâ”€â”€ MANIFEST.in
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â”œâ”€â”€ results # All results are here.
â”‚Â Â  â”œâ”€â”€ baseline
â”‚Â Â  â”œâ”€â”€ basemodel_results
â”‚Â Â  â”œâ”€â”€ cognitive_overload_effect_to_cause
â”‚Â Â  â”œâ”€â”€ cognitive_overload_veiled_attack
â”‚Â Â  â”œâ”€â”€ FigStep
â”‚Â Â  â””â”€â”€ VRP-results
â”œâ”€â”€ setup.cfg
â”œâ”€â”€ src
â”‚Â Â  â”œâ”€â”€ resp_gen_ai
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ api.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ cli.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ constants.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ datasets
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ hydra_files
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ __main__.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ metrics
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ models # Model settings are here.
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ __pycache__
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ py.typed
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ tasks
â”‚Â Â  â”‚Â Â  â””â”€â”€ version.py
â”‚Â Â  â””â”€â”€ resp_gen_ai.egg-info
â”œâ”€â”€ structure.txt
â”œâ”€â”€ tests
â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â  â””â”€â”€ test_version.py
â”œâ”€â”€ tox.ini
â””â”€â”€ use_cases
    â”œâ”€â”€ evalutor_llama_guard_3_8B.py # Evaluator llama guard entrance
    â”œâ”€â”€ evalutor_strong_reject_one_by_one.py # Evaluator strong reject entrance
    â”œâ”€â”€ jailbreak
    â”‚Â Â  â”œâ”€â”€ baseline
    â”‚Â Â  â”œâ”€â”€ cognitive_overload
    â”‚Â Â  â”œâ”€â”€ FigStep
    â”‚Â Â  â”œâ”€â”€ Multimodal_Pragmatic_Evaluation
    â”‚Â Â  â”œâ”€â”€ run_models # Entrace of the repository
    â”‚Â Â  â””â”€â”€ VRP_query_specific
    â””â”€â”€ load_inference
```
## ğŸ›  Environment Setup

Make sure you are using **Python 3.10.16**.

## ğŸ“¦ Installation

Clone the repository and install the package in editable mode:

```bash
git clone https://github.com/wowoke/REBench.git
cd REBench
pip install -e .
```

## âœ… Usage

After installation, you can start using the REBench toolkit.  
(You may add instructions here for running inference, benchmarking models, or specifying configuration.)

## ğŸ“‚ Dataset Preparation

Before running the model, please make sure to download the dataset: **REBench_Dataset**.

In the Python script under `run_models` (e.g., `use_cases/jailbreak/run_models/jailbreak_vlm_R1_batch_vllm.py`),  
you need to set the following parameters before execution:

- The attack method you want to use (`jailbreak_method`)
- The path to the CSV data file (`csv_path`)
- The path to the image folder (`images_path`)

For example:

```python
csv_path = "REBench_Dataset/FigStep/REBench_FigStep.csv"
images_path = "REBench_Dataset/FigStep/FigStep_Images"
jailbreak_method = "FigStep"
```

Once set, run the script:

```bash
python use_cases/jailbreak/run_models/jailbreak_vlm_R1_batch_vllm.py
```

## ğŸ§  Running on Non-vLLM Models

For models that **do not support vLLM** (such as `Visual-RFT`, `Align-DSV`, `Open-R1-Multimodal`),  
you need to use the **`accelerate`** library, which should already be available in your environment.  
No extra installation is required.

Before launching, configure accelerate using:

```bash
accelerate config
```

This step will generate a `.yaml` configuration file under the default path.  
Based on your actual setup (e.g., number of GPUs), choose appropriate options.

Then launch the script using:

```bash
accelerate launch use_cases/jailbreak/run_models/jailbreak_pku_dsv_hf_batch.py
```

## ğŸš€ Talbe of Model Inference Method

| Model                              | Inference Method                                                                                       | Inference Mode |
|------------------------------------|--------------------------------------------------------------------------------------------------------|----------------|
| Align-DSV                          | accelerate launch use_cases/jailbreak/run_models/jailbreak_pku_dsv_hf_batch.py                         | accelerate     |
| QVQ-72B-Preview                    | python use_cases/jailbreak/run_models/jailbreak_qvq_72b_vllm_batch.py                                  | vLLM           |
| Skywork-R1V                        | python use_cases/jailbreak/run_models/jailbreak_skywork_R1V-vllm_batch.py                              | vLLM           |
| Visual-RFT                         | accelerate launch use_cases/jailbreak/run_models/jailbreak_visual_RFT_batch_hf.py                      | accelerate     |
| VLM-R1                             | accelerate launch use_cases/jailbreak/run_models/jailbreak_vlm_R1_batch_vllm.py                        | accelerate     |
| Open-R1-Multimodal                 | accelerate launch use_cases/jailbreak/run_models/jailbreak_open_r1_multimodal_hf_batch.py              | accelerate     |
| DeepSeek-R1-Distill-Llama-8B       | python use_cases/jailbreak/run_models/basemodels/deepseek-R1-Distill-Llama-8B.py                       | vLLM           |
| DeepSeek-R1-Distill-Qwen-32B       | python use_cases/jailbreak/run_models/basemodels/deepseek-R1-Distill-Qwen-32B.py                       | vLLM           |
| Qwen2-VL-7B-Instruct               | python use_cases/jailbreak/run_models/basemodels/qwen2-vl-7b-instruct-vllm.py                          | vLLM           |
| QVQ-72B-Preview                    | python use_cases/jailbreak/run_models/basemodels/qwen2-vl-72b-vllm.py                                  | vLLM           |
| Qwen2.5-VL-3B-Instruct             | python use_cases/jailbreak/run_models/basemodels/qwen2.5-vl-3B.py                                      | vLLM           |

## ğŸ§ª How to Use the Judge Model?

To use only the **Judge Model**, simply specify the folder path where the model output results are stored in one of the following scripts:

- `REBench/use_cases/evalutor_llama_guard_3_8B.py`
- `REBench/use_cases/evalutor_strong_reject_one_by_one.py`

For example, in the script, modify the `folder_path` as follows:

```python
folder_path = ''

# redefine folder_path in the Python script
folder_path = 'models_results'
```

Once the path is correctly set, run one of the Python scripts below:

```bash
python use_cases/evalutor_llama_guard_3_8B.py
# or
python use_cases/evalutor_strong_reject_one_by_one.py
```

## ğŸ” Pragmatic Evaluation Workflow

### 1. Clone the **Multimodal Pragmatic** repo and grab the image assets
```bash
git clone https://github.com/multimodalpragmatic/multimodalpragmatic.git
```
Save the **absolute path** to this `images` folderâ€”youâ€™ll paste it into the scripts below.

---

### 2. Build the zero-shot CSV
Edit  
`REBench/use_cases/jailbreak/Multimodal_Pragmatic_Evaluation/1_make_csv_file.py`  
and replace the placeholder on **line 27** with your `images` path.
Then run:
```bash
python REBench/use_cases/jailbreak/Multimodal_Pragmatic_Evaluation/1_make_csv_file.py
```
This creates `multimodalpragmatic_zero_shot.csv`.

---

### 3. Run your models
Open  
`use_cases/jailbreak/Multimodal_Pragmatic_Evaluation/2_run_code.py`  

* On **line 9**, point it to the CSV you just generated.  
* Select the model(s) you want to evaluate inside the script.

```bash
python REBench/use_cases/jailbreak/Multimodal_Pragmatic_Evaluation/2_run_code.py
```
The script outputs a **folder of JSON files**, one per model.

---

### 4. Check QWQ-32B alignment
Insert the path to that output folder in  
`use_cases/jailbreak/Multimodal_Pragmatic_Evaluation/3_evaluation_QWQ.py` (line 28) and run:

```bash
python use_cases/jailbreak/Multimodal_Pragmatic_Evaluation/3_evaluation_QWQ.py
```

---

### 5. Formalize the raw judgements
If the JSON schema still needs tweaking, edit  
`use_cases/jailbreak/Multimodal_Pragmatic_Evaluation/4_formalize_the_judgement.py` (line 5) with the file to be reformatted, then run:

```bash
python use_cases/jailbreak/Multimodal_Pragmatic_Evaluation/4_formalize_the_judgement.py
```

---

### 6. Compute the evaluation matrix
Add the **formalized JSON** path to  
`use_cases/jailbreak/Multimodal_Pragmatic_Evaluation/5_evaluation_matrix.py`, then execute:

```bash
python use_cases/jailbreak/Multimodal_Pragmatic_Evaluation/5_evaluation_matrix.py
```

The final script outputs a JSON file containing the **quantitative evaluation metrics** for each model.
